{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "punchline_detection",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshat3011/punchline-detection-hierarchical-fusion/blob/master/punchline_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMiyP78go6tD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "b6c7de50-649d-469c-8aa9-f1932e9177d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ns_CFW2qsdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52c1bac0-f9e6-4fa9-ca7f-cacaee9ac76d"
      },
      "source": [
        "#path in drive to UR-FUNNY data\n",
        "%cd gdrive/My\\ Drive/HF-Network/UR-FUNNY"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/HF-Network/UR-FUNNY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aonFVnXaq7kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import humor_dataloader as hd\n",
        "import pickle \n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s33s10xbpZMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading data\n",
        "data_folds_file= \"data_folds.pkl\"\n",
        "data_folds= hd.load_pickle(data_folds_file)\n",
        "train=data_folds['train']\n",
        "dev=data_folds['dev']\n",
        "test=data_folds['test']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQVz1cEqpjf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a69586e7-a1f2-43f7-8f5c-3e764eaafb01"
      },
      "source": [
        "len(train)+len(dev)+len(test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcZICBQ-8YxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_dir = \"/content/gdrive/My Drive/HF-Network/output/\"\n",
        "weights_dir = \"/content/gdrive/My Drive/HF-Network/pretrained_weights/\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI0Eu-m8NqQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_len = {'test': len(test),'train': len(train)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9OUf8AarRi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = hd.HumorDataset(train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP97ydULrTq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_set = hd.HumorDataset(dev)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir9n8aFRrtDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set = hd.HumorDataset(test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyDwDFHrrvQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 10\n",
        "train_dataloader = hd.DataLoader(train_set, batch_size=batch, shuffle=True)\n",
        "dev_dataloader = hd.DataLoader(dev_set, batch_size=batch, shuffle=True)\n",
        "test_dataloader = hd.DataLoader(test_set, batch_size=batch, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH42GvIjr6Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimension equilization dimension\n",
        "dim_proj = 400 \n",
        "text_dim, audio_dim,video_dim = 300, 81, 75\n",
        "dim = audio_dim + video_dim + text_dim\n",
        "max_context_len = 5\n",
        "max_sen_len = 20"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNJl3mpOr9d7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop(a):\n",
        "    return a[:,:,:, 0:text_dim],a[:, :, :, text_dim:(text_dim + audio_dim)], a[:, :, :, (text_dim+audio_dim):dim]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41N1CPltzZmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_1(a):\n",
        "    return a[:,:, 0:text_dim],a[:,:, text_dim:(text_dim + audio_dim)],a[:,:,(text_dim + audio_dim):dim]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5USEvDuRr-LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class hadamard(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(hadamard, self).__init__()\n",
        "        self.w1 = nn.Parameter(torch.zeros(6,max_sen_len,dim_proj))\n",
        "        self.w2 = nn.Parameter(torch.zeros(6,max_sen_len,dim_proj))\n",
        "        self.bias = nn.Parameter(torch.zeros(6,max_sen_len,dim_proj))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[0] * self.w1 + x[1] * self.w2 + self.bias"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuo0lgERsIZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For dimension equalization of text modality \n",
        "class fc1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(fc1, self).__init__()\n",
        "        self.fc = nn.Linear(text_dim, dim_proj)\n",
        "    def forward(self,x):\n",
        "        return self.fc(x)\n",
        "\n",
        "#For dimension equalization of audio modality \n",
        "class fc2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(fc2, self).__init__()\n",
        "        self.fc = nn.Linear(audio_dim, dim_proj)\n",
        "    def forward(self,x):\n",
        "        return self.fc(x)\n",
        "\n",
        "#For dimension equalization of video modality \n",
        "class fc3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(fc3, self).__init__()\n",
        "        self.fc = nn.Linear(video_dim, dim_proj)\n",
        "    def forward(self,x):\n",
        "        return self.fc(x)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQhw0kVusJAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bimodal Fusion for text and audio\n",
        "class bimodal_1_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(bimodal_1_2, self).__init__()\n",
        "        self.fc1 = fc1()\n",
        "        self.fc2 = fc2()\n",
        "        self.act = nn.Tanh()\n",
        "        self.hadamard = hadamard()\n",
        "        self.fcp = nn.Linear(max_sen_len*dim_proj, 2)\n",
        "        self.dropout = nn.Dropout(p = 0.5)\n",
        "    \n",
        "    def forward(self,out1,out2,out3):\n",
        "        bs = out1.shape[0]\n",
        "        out1 = self.fc1(out1)\n",
        "        out2 = self.fc2(out2)\n",
        "        out1 = self.act(out1)\n",
        "        out2 = self.act(out2)\n",
        "        out1  = self.dropout(out1)\n",
        "        out2 = self.dropout(out2)\n",
        "        out  = self.hadamard([out1,out2])\n",
        "        out = self.act(out)\n",
        "        out_f = out.view(bs,6,-1)\n",
        "        out_f = self.fcp(out_f)\n",
        "        return out_f, out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1hTo3DoJ9fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bimodal Fusion for audio and video\n",
        "class bimodal_2_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(bimodal_2_3, self).__init__()\n",
        "        self.fc2 = fc2()\n",
        "        self.fc3 = fc3()\n",
        "        self.act = nn.Tanh()\n",
        "        self.hadamard = hadamard()\n",
        "        self.crop = crop\n",
        "        self.fcp = nn.Linear(max_sen_len*dim_proj, 2)\n",
        "        self.dropout = nn.Dropout(p = 0.5)\n",
        "    \n",
        "    def forward(self,out1,out2,out3):\n",
        "        bs = out2.shape[0]\n",
        "        out2 = self.fc2(out2)\n",
        "        out3 = self.fc3(out3)\n",
        "        out2 = self.act(out2)\n",
        "        out3 = self.act(out3)\n",
        "        out2 = self.dropout(out2)\n",
        "        out3 = self.dropout(out3)\n",
        "        out  = self.hadamard([out2,out3])\n",
        "        out = self.act(out)\n",
        "        out_f = out.view(bs,6,-1)\n",
        "        out_f = self.fcp(out_f)\n",
        "        return out_f,out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8jtx_nsauU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bimodal Fusion for text and video\n",
        "class bimodal_1_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(bimodal_1_3, self).__init__()\n",
        "        self.fc1 = fc1()\n",
        "        self.fc3 = fc3()\n",
        "        self.act = nn.Tanh()\n",
        "        self.hadamard = hadamard()\n",
        "        self.crop = crop\n",
        "        self.fcp = nn.Linear(max_sen_len*dim_proj, 2)\n",
        "        self.dropout = nn.Dropout(p = 0.5)\n",
        "    \n",
        "    def forward(self,out1,out2,out3): #dim of each is batch_size*110*100\n",
        "        bs = out1.shape[0]\n",
        "        out1 = self.fc1(out1)\n",
        "        out3 = self.fc3(out3)\n",
        "        out1 = self.act(out1)\n",
        "        out3 = self.act(out3)\n",
        "        out1 = self.dropout(out1)\n",
        "        out3 = self.dropout(out3)\n",
        "        out  = self.hadamard([out1,out3])\n",
        "        out = self.act(out)\n",
        "        out_f = out.view(bs,6,-1)\n",
        "        out_f = self.fcp(out_f)\n",
        "        return out_f,out"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i3al5my62K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loaders = {\"train\": train_dataloader, \"test\": test_dataloader}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGHMHaAosMqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net1 = bimodal_1_2()\n",
        "net2 = bimodal_2_3()\n",
        "net3 = bimodal_1_3()\n",
        "num_epochs = 150"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDl_bkipsR2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(net1.parameters(), lr = 0.0001)\n",
        "optimizer2 = optim.Adam(net2.parameters(), lr = 0.0001)\n",
        "optimizer3 = optim.Adam(net3.parameters(), lr = 0.0001)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAF0E1RLERH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v8IpN7fia_Fq",
        "colab": {}
      },
      "source": [
        "#function to train bimodal components\n",
        "def train_bimodal(model,model_name,optimizer):\n",
        "\n",
        "  running_loss = 0\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model = model.to(device)\n",
        "\n",
        "  print(\"Training Network: \" + model_name)\n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"Epoch :\" + str(epoch+1))\n",
        "    print(\"**********************************\")\n",
        "    for phase in ['train','test']:\n",
        "      comb_y = []\n",
        "      comb_o  = []\n",
        "\n",
        "      if phase == 'train':\n",
        "        model.train(True)  # Set model to training mode\n",
        "      else:\n",
        "        model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "      for  batch_idx, batch in enumerate(data_loaders[phase], 0):\n",
        "        x_p,x_c,y = map(lambda x: x.to(device), batch)\n",
        "        x_p = torch.unsqueeze(x_p, dim=1)\n",
        "        combined = torch.cat([x_c, x_p], dim=1)\n",
        "        # get vectors for each modality  \n",
        "        x1,x2,x3 = crop(combined)\n",
        "        optimizer.zero_grad()\n",
        "        output,_ = model(x1,x2,x3)\n",
        "        bs = x1.shape[0]\n",
        "        output = output.to(device)\n",
        "        op = torch.zeros(0).to(device)\n",
        "        count = 0\n",
        "        output = output.view(-1,2)\n",
        "\n",
        "        for t in output:\n",
        "          if(count%6==5):\n",
        "            op = torch.cat([op,t],dim = 0)\n",
        "          count = count + 1\n",
        "\n",
        "        op = op.view(-1,2)\n",
        "        op_sigm = torch.sigmoid(op)\n",
        "        y = y.to(device=device, dtype=torch.int64)\n",
        "        y = torch.squeeze(y, -1)\n",
        "\n",
        "        # for calculating accuracy after each epoch\n",
        "        for o in y:\n",
        "          comb_y.append(o.item())\n",
        "        for p in op_sigm:\n",
        "          if(p[0].item() > p[1].item()):\n",
        "            comb_o.append(0)\n",
        "          else:\n",
        "            comb_o.append(1)\n",
        "\n",
        "        loss = criterion(op,y)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if(phase == 'train'):\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      print(phase + ' loss: ' + str(running_loss/data_len[phase]))\n",
        "      running_loss = 0.0\n",
        "      print( phase + ' accuracy: ' + str(accuracy_score(comb_y,comb_o)))\n",
        "    if((epoch+1)%5 == 0):\n",
        "      print(\"Saving Model\")\n",
        "      torch.save(model.state_dict(), output_dir + \"%s_%d.pth\" % (model_name,epoch+1))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxUnvVU08Kp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD8fdwFzC2cj",
        "colab_type": "text"
      },
      "source": [
        "Net1 text + acoustic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9qOjGpqlh_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bimodal(net1,\"net1\",optimizer1)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHR8k10sbSR9",
        "colab_type": "text"
      },
      "source": [
        "NET 2 acoustic + visual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKYDqGRZsd8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bimodal(net2,\"net2\",optimizer2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZCkXE5YaIJR",
        "colab_type": "text"
      },
      "source": [
        "NET 3 text  + visual\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC_zaPssgS81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bimodal(net3,\"net3\",optimizer3) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbTaIXe5SDlO",
        "colab_type": "text"
      },
      "source": [
        "Loading best bimodal models for trimodal fusion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZIwdMTeLlOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "564db89e-cfb9-4833-c415-2c01194d7799"
      },
      "source": [
        "net3.load_state_dict(torch.load(weights_dir + \"net3.pth\"))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLocoPBpZf8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a525241-cbf5-4dcb-9b83-9a8cd17d05e8"
      },
      "source": [
        "net1.load_state_dict(torch.load(weights_dir + \"net1.pth\"))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6m6UsclZiqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0bafdb2-7041-4ee3-e607-587c25cfcbb0"
      },
      "source": [
        "net2.load_state_dict(torch.load(weights_dir + \"net2.pth\"))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtAvcSs1nldu",
        "colab_type": "text"
      },
      "source": [
        "TRIMODAL FUSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me3MlX-j4zoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_dim = 200\n",
        "pro_dim = 900"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Hq4jCEgu9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class tri_hadamard(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(tri_hadamard, self).__init__()\n",
        "        self.w1 = nn.Parameter(torch.zeros(6,max_sen_len,dim_proj))\n",
        "        self.w2 = nn.Parameter(torch.zeros(6,max_sen_len,dim_proj))\n",
        "        self.w3 = nn.Parameter(torch.zeros(6,max_sen_len,dim_proj))\n",
        "        self.bias = nn.Parameter(torch.zeros(6,max_sen_len,dim_proj))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[0] * self.w1 + x[1] * self.w2 + x[2] * self.w3 + self.bias"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTwYurbQRjke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Context Modelling Network\n",
        "class tri_GRU(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(tri_GRU, self).__init__()\n",
        "      self.input_dim = max_sen_len*dim_proj\n",
        "      self.hidden_dim = gru_dim\n",
        "      self.drop_prob = 0.4\n",
        "      self.gru = nn.GRU(self.input_dim, self.hidden_dim, dropout= self.drop_prob,num_layers = 1)\n",
        "      self.dropout = nn.Dropout(p = 0.5)\n",
        "      self.act = nn.Tanh()\n",
        "      self.fcp = nn.Linear(max_sen_len*dim_proj,pro_dim )\n",
        "\n",
        "  def forward(self,x):\n",
        "      x_p = x[:,1,:]\n",
        "      x_c = x[:,1:6,:]\n",
        "      x = self.gru(x_c)\n",
        "      x = x[0]\n",
        "      x = x[:,4,:]\n",
        "      x = self.act(x)\n",
        "      x_p = self.fcp(x_p)\n",
        "      x = torch.cat([x,x_p],dim = 1)\n",
        "      return x"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvAFHF0Va5-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class trimodal(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(trimodal, self).__init__()\n",
        "        self.hadamard = tri_hadamard()\n",
        "        self.act = nn.Tanh()\n",
        "        self.f1 = nn.Linear(max_sen_len*dim_proj, 450)\n",
        "        self.fcp = nn.Linear(gru_dim+pro_dim, 2)\n",
        "        self.dropout = nn.Dropout(p = 0.3)\n",
        "        self.context_modelling = tri_GRU()\n",
        "        self.crop = crop\n",
        "        self.net1 = net1\n",
        "        self.net2 = net2\n",
        "        self.net3 = net3\n",
        "    \n",
        "    def forward(self,x1,x2,x3):\n",
        "        _,out1 = self.net1(x1,x2,x3)\n",
        "        _,out2 = self.net2(x1,x2,x3)\n",
        "        _,out3 = self.net3(x1,x2,x3)\n",
        "        bs = out2.shape[0]\n",
        "        out1 = self.dropout(out1)\n",
        "        out2 = self.dropout(out2)\n",
        "        out3 = self.dropout(out3)\n",
        "        out = self.hadamard([out1,out2,out3])\n",
        "        out = self.act(out)\n",
        "        out = out.view(bs,6,-1)\n",
        "        out = self.context_modelling(out)\n",
        "        out = self.fcp(out) \n",
        "        return out"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-gzaWGblKqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "outputId": "fa9d6142-76c6-4a36-dc44-e7b5e4b17bf5"
      },
      "source": [
        "trimodal()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "trimodal(\n",
              "  (hadamard): tri_hadamard()\n",
              "  (act): Tanh()\n",
              "  (f1): Linear(in_features=8000, out_features=450, bias=True)\n",
              "  (fcp): Linear(in_features=1100, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (context_modelling): tri_GRU(\n",
              "    (gru): GRU(8000, 200, dropout=0.4)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (act): Tanh()\n",
              "    (fcp): Linear(in_features=8000, out_features=900, bias=True)\n",
              "  )\n",
              "  (net1): bimodal_1_2(\n",
              "    (fc1): fc1(\n",
              "      (fc): Linear(in_features=300, out_features=400, bias=True)\n",
              "    )\n",
              "    (fc2): fc2(\n",
              "      (fc): Linear(in_features=81, out_features=400, bias=True)\n",
              "    )\n",
              "    (act): Tanh()\n",
              "    (hadamard): hadamard()\n",
              "    (fcp): Linear(in_features=8000, out_features=2, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (net2): bimodal_2_3(\n",
              "    (fc2): fc2(\n",
              "      (fc): Linear(in_features=81, out_features=400, bias=True)\n",
              "    )\n",
              "    (fc3): fc3(\n",
              "      (fc): Linear(in_features=75, out_features=400, bias=True)\n",
              "    )\n",
              "    (act): Tanh()\n",
              "    (hadamard): hadamard()\n",
              "    (fcp): Linear(in_features=8000, out_features=2, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (net3): bimodal_1_3(\n",
              "    (fc1): fc1(\n",
              "      (fc): Linear(in_features=300, out_features=400, bias=True)\n",
              "    )\n",
              "    (fc3): fc3(\n",
              "      (fc): Linear(in_features=75, out_features=400, bias=True)\n",
              "    )\n",
              "    (act): Tanh()\n",
              "    (hadamard): hadamard()\n",
              "    (fcp): Linear(in_features=8000, out_features=2, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4JVttwqWlWA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "13ff878f-e06b-49e4-8506-a4bbda071ac2"
      },
      "source": [
        "tri_net = trimodal()\n",
        "num_epochs = 150\n",
        "batch=10"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "blIFtwFJlWBJ",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "tri_optimizer = optim.Adam(tri_net.parameters(), lr=0.00001)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6giYsEO7EXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc60497b-d9dd-4761-8bc9-49dea34e352c"
      },
      "source": [
        "tri_net.load_state_dict(torch.load(weights_dir + 'tri_net.pth'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNYEwV6afZfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training Trimodal component\n",
        "running_loss = 0\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tri_net = tri_net.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  print(\"Epoch :\" + str(epoch+1))\n",
        "  print(\"**********************************\")\n",
        "  for phase in ['train','test']:\n",
        "    comb_y = []\n",
        "    comb_o  = []\n",
        "    if phase == 'train':\n",
        "      tri_net.train(True)  # Set model to training mode\n",
        "    else:\n",
        "      tri_net.train(False)  # Set model to evaluate mode\n",
        "\n",
        "    for  batch_idx, batch in enumerate(data_loaders[phase], 0):\n",
        "      x_p,x_c,y = map(lambda x: x.to(device), batch)\n",
        "      x_p = torch.unsqueeze(x_p, dim=1)\n",
        "      combined = torch.cat([x_c, x_p], dim=1)\n",
        "      x1,x2,x3 = crop(combined)\n",
        "\n",
        "      tri_optimizer.zero_grad()\n",
        "      output = tri_net(x1,x2,x3)\n",
        "      bs = x1.shape[0]\n",
        "      \n",
        "      output = output.to(device)\n",
        "      op_sigm = torch.sigmoid(output)\n",
        "      y = y.to(device=device, dtype=torch.int64)\n",
        "      output = output.view(-1,2)\n",
        "    \n",
        "      y = torch.squeeze(y, -1)\n",
        "      for o in y:\n",
        "        comb_y.append(o.item())\n",
        "      for p in op_sigm:\n",
        "        if(p[0].item()>p[1].item()):\n",
        "          comb_o.append(0)\n",
        "        else:\n",
        "          comb_o.append(1)     \n",
        "        \n",
        "      loss = criterion(output,y)\n",
        "      if(phase == 'train'):\n",
        "        loss.backward()\n",
        "        tri_optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(phase + ' loss: ' + str(running_loss/data_len[phase]))\n",
        "    running_loss = 0.0\n",
        "    print( phase + ' accuracy: ' + str(accuracy_score(comb_y,comb_o)))\n",
        "  if((epoch+1)%1 == 0):\n",
        "    print(\"Saving Model\")\n",
        "    torch.save(tri_net.state_dict(), output_dir + 'trimodal_%d.pth' % (epoch+1))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abTxRdemmoV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBnllKq06anY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}